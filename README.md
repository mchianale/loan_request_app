# Processus d‚Äô√âvaluation des Demandes de Pr√™t

Ce TD a pour objectif d‚Äôimpl√©menter un processus m√©tier de gestion des demandes de pr√™t
immobilier en utilisant des concepts avanc√©s de microservices, de t√¢ches asynchrones, et de
messagerie interservices. Les √©tudiants devront appliquer des notions de coroutines, files de
messages, t√¢ches en arri√®re-plan et √©v√©nements pour assurer une ex√©cution efficace et
distribu√©e du processus.

## Demo

---

## Architecture 
![global_sch](https://github.com/mchianale/loan_request_app/blob/main/docs/main_archi.png)

**1Ô∏è‚É£ MongoDB (Base de donn√©es) :** 
- Base de donn√©es `NoSQL` utilis√©e pour stocker les informations des clients (`users`) et g√©rer leurs demandes de pr√™t (`loans`).
- Utilise clients asynchrones et synchrones pour g√©rer les requ√™tes efficacement.
- Seulement accessible par l'API [`userBackEnd`](https://github.com/mchianale/loan_request_app/tree/main/userBackEnd).

---

**2Ô∏è‚É£ [User Backend](https://github.com/mchianale/loan_request_app/tree/main/userBackEnd) (FastAPI) :**
- API backend construite avec FastAPI pour g√©rer **les connexion et inscription, la gestion de compte et la cr√©ation de demandes de pr√™t.**
- Produit des logs et des demandes de pr√™t vers `Kafka`.

---

**3Ô∏è‚É£ Zookeeper & Kafka Brokers :**
- `Zookeeper` : Coordonne les brokers Kafka.
- `Kafka Brokers` :
  1. üì® Re√ßoivent des demandes de pr√™t du backend utilisateur.
  2. üîÑ Distribuent ces demandes aux services de traitement via topics Kafka.
  3. üì§ Produisent des logs vers ELK pour la centralisation des journaux.

---

**4Ô∏è‚É£ [ELK Stack](https://github.com/mchianale/loan_request_app/tree/main/logstash) (Logstash, Elasticsearch, Kibana) :**  
- Centralise et visualise les logs du syst√®me.  
- Composants principaux :
  - üìä **Logstash** : R√©cup√®re et traite les logs de Kafka.  
  - üîç **Elasticsearch** : Stocke les logs pour une recherche efficace.  
  - üìà **Kibana** : Fournit une interface de visualisation des logs et des m√©triques de l'application.  

---

**5Ô∏è‚É£ [Celery App](https://github.com/mchianale/loan_request_app/tree/main/celeryApp) (Traitement Asynchrone) :**  
- Gestion du traitement parall√®le via `Celery` et `RabbitMQ`.  
- Ex√©cute les t√¢ches critiques de validation et d‚Äô√©valuation des pr√™ts :  
  - ‚úÖ √âvaluation de l'historique de cr√©dit et du profil ([**creditCheckApp - FastAPI**](https://github.com/mchianale/loan_request_app/tree/main/creditCheckApp)).  
  - ‚úÖ √âvaluation du projet immobilier ([**propertyCheckApp - FastAPI**](https://github.com/mchianale/loan_request_app/tree/main/propertyCheckApp)).  
  - ‚úÖ G√©n√©ration de la d√©cision finale et du calendrier de remboursement ([**decisionApp - FastAPI**](https://github.com/mchianale/loan_request_app/tree/main/decisionApp)).  
- Produit des logs vers `Kafka` pour centralisation et monitoring.  
- **Celery Broker** : `RabbitMQ`
- **Celery Backend** : `Redis`

---

**6Ô∏è‚É£ [Loan Notification App](https://github.com/mchianale/loan_request_app/tree/main/loanNotificationApp) (FastAPI + WebSockets) :**  
- Fournit une API `WebSockets` pour notifier les utilisateurs du statut de leur demande de pr√™t en **temps r√©el**.  
- Se connecte au backend Celery et √† Kafka pour r√©cup√©rer les mises √† jour et envoyer des notifications.  

---

**7Ô∏è‚É£ [Streamlit Frontend](https://github.com/mchianale/loan_request_app/tree/main/stFrontEnd) :**  
- Interface utilisateur interactive permettant aux utilisateurs de :  
  - üîë **Se connecter et g√©rer leur compte**.  
  - üè¶ **Cr√©er une nouvelle demande de pr√™t**.  
  - üîé **Suivre en temps r√©el l‚Äô√©valuation de leur demande de pr√™t**.  
  - üìä **Visualiser les d√©cisions de cr√©dit et l'historique des pr√™ts**.  
  - üì° **Recevoir des mises √† jour instantan√©es via `WebSockets`**.  

---

## Cycle de vie d'une demande
![global_sch](https://github.com/mchianale/loan_request_app/blob/main/docs/loan_life.png)

Lorsqu'un utilisateur est connect√©, il peut cr√©er une nouvelle demande de pr√™t. Si la cr√©ation est r√©ussie, la demande est enregistr√©e dans la base de donn√©es `MongoDB` et est annot√©e comme `Pending`.

Simultan√©ment, un message `Kafka` est produit vers le topic `loan_topic`. L'application `Celery`, qui fonctionne en continu, consomme ces messages `Kafka`. Lorsqu'une nouvelle demande est d√©tect√©e, un groupe de t√¢ches est lanc√©.

**√âtapes du traitement :**
- **√âvaluation en parall√®le :**
  1. L'√©valuation du profil et du cr√©dit (via `creditCheckApp - FastAPI`).
  2. '√©valuation du projet immobilier (via `propertyCheckApp - FastAPI`).
  3. Ces √©valuations sont effectu√©es simultan√©ment.
- **Validation des √©valuations :**
  1. Si l'une des deux t√¢ches √©choue ou si la demande est refus√©e, le processus est arr√™t√© imm√©diatement, et la demande de pr√™t est mise √† jour en base de donn√©es avec le statut Denied ou Cancelled.
- **Validation finale :**
  1. Si les deux √©valuations sont approuv√©es, une derni√®re t√¢che est ex√©cut√©e pour retourner la d√©cision finale et g√©n√©rer un plan de remboursement (via `decisionApp - FastAPI`).
  2. La demande de pr√™t est alors mise √† jour avec le statut final : `Denied` ou `Approved`.
- **Notification en temps r√©el :**
  1. Chaque t√¢che envoie des notifications en temps r√©el via WebSockets √† l'application LoanDecisionApp, permettant aux utilisateurs d'√™tre inform√©s en direct de l'√©tat de l'√©valuation de leur demande.

---

## R√©utilsiation 
### Le fichier `.env`
Cr√©er un fichier `.env`:
```
# Mongodb
MONGO_INITDB_ROOT_USERNAME=myuser
MONGO_INITDB_ROOT_PASSWORD=<set_a_password>
DATABASE_NAME=user_db
# token bearer
JWT_SECRET_KEY=<secret_key_for_decrypt_session_token>
ACCESS_TOKEN_EXPIRE_MINUTES=30
# ELK
ELASTIC_USERNAME=elastic
ELASTIC_PASSWORD=<set_a_password>
ELASTICSEARCH_SERVICEACCOUNTTOKEN=<token_for_elastic_search>
# Kafka kafka-0:9092,kafka-1:9092,kafka-2:9092
KAFKA_BROKERS=kafka-0:9092,kafka-1:9092,kafka-2:9092
# Celery
REDIS_HOST=kredis
REDIS_PORT=6379
REDIS_PASSWORD=<set_a_password>
REDIS_CELERY_DB_INDEX=10
RABBITMQ_HOST=krabbitmq
RABBITMQ_USERNAME=rabbitmq
RABBITMQ_PASSWORD=<set_a_password>  
RABBITMQ_PORT=5672
LOAN_TOPIC=loan_topic
CREDIT_CHECK_URL=http://credit-check-app-service:8001/evaluate_credit
PROPERTY_CHECK_URL=http://property-check-app-service:8002/evaluate_property
DECISION_URL=http://decision-app-service:8003/loan_decision
NOTIFICATION_URL=http://loan-notification-service:8004/notify
UPDATE_LOAN_URL=http://user-backend-service:8000/update_loan_request
# ADMIN_PASSWORD to notify using LoanNotifyApp
ADMIN_PASSWORD=<admin_password_for_notification_security>
```

### Config de `RabbitMQ`
Cr√©er `rabbitmq.conf`:
```conf
default_user=rabbitmq
default_pass=<set_a_password>  
```


### Premier lancement
1. Lancer une premi√®re fois `docker-compose`:
```bash
docker-compose up -d
```

2. Cr√©er un token `Elastic-search` pour `Kibana`:
```bash
curl -X POST -u elastic:<your_password> "localhost:9200/_security/service/elastic/kibana/credential/token/kibana_token?pretty"
```

3. Modifier ensuite le fichier `.env`:
```
ELASTICSEARCH_SERVICEACCOUNTTOKEN=<le token retourn√©>
```

4. Relancer `docker-compose` avec la mise √† jour:
```
docker-compose --env-file .env up -d
```
Si tout fonctionne, acc√©dez √† [kibana](http://localhost:5601/app/home#/).

### Lancer le front
```bash
streamlit run stFrontEnd/main.py
```

### R√©initialiser les logs
Supprimer l'index `logs` d'`Elastic-search`:
```bash
curl -X DELETE -u elastic:<your_password>  "http://localhost:9200/logs"
```

---

## Kibana Dashboard

# a faire 
## Test
## Kubernetes
## dashboard

## README
## rapport
### Intro
### Architecture globale 
### Gestion des uilisateurs (login / singup token de session etc.. )
### Service de demande de pret (chaque service & celeri)
### Notification en tmpes reel (websocket et celeri)
### Interac graphiqye utilisateur
### Centralisation des logs
### Cloud Kubernetes
### Test 



