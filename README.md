# Processus d‚Äô√âvaluation des Demandes de Pr√™t

Ce TD a pour objectif d‚Äôimpl√©menter un processus m√©tier de gestion des demandes de pr√™t
immobilier en utilisant des concepts avanc√©s de microservices, de t√¢ches asynchrones, et de
messagerie interservices. Les √©tudiants devront appliquer des notions de coroutines, files de
messages, t√¢ches en arri√®re-plan et √©v√©nements pour assurer une ex√©cution efficace et
distribu√©e du processus.

## Demo

---

## Architecture 
![global_sch](https://github.com/mchianale/loan_request_app/blob/main/docs/main_archi.png)

**1Ô∏è‚É£ MongoDB (Base de donn√©es) :** 
- Base de donn√©es `NoSQL` utilis√©e pour stocker les informations des clients (`users`) et g√©rer leurs demandes de pr√™t (`loans`).
- Utilise clients asynchrones et synchrones pour g√©rer les requ√™tes efficacement.
- Seulement accessible par l'API [`userBackEnd`](https://github.com/mchianale/loan_request_app/tree/main/userBackEnd).

**2Ô∏è‚É£ [User Backend](https://github.com/mchianale/loan_request_app/tree/main/userBackEnd) (FastAPI) :**
- API backend construite avec FastAPI pour g√©rer **les connexion et inscription, la gestion de compte et la cr√©ation de demandes de pr√™t.**
- Produit des logs et des demandes de pr√™t vers `Kafka`.

**3Ô∏è‚É£ Zookeeper & Kafka Brokers :**
- `Zookeeper` : Coordonne les brokers Kafka.
- `Kafka Brokers` :
  1. üì® Re√ßoivent des demandes de pr√™t du backend utilisateur.
  2. üîÑ Distribuent ces demandes aux services de traitement via topics Kafka.
  3. üì§ Produisent des logs vers ELK pour la centralisation des journaux.


---

## R√©utilsiation 

---


# a faire 
## Test
## Kubernetes
## dashboard

## README
## rapport
### Intro
### Architecture globale 
### Gestion des uilisateurs (login / singup token de session etc.. )
### Service de demande de pret (chaque service & celeri)
### Notification en tmpes reel (websocket et celeri)
### Interac graphiqye utilisateur
### Centralisation des logs
### Cloud Kubernetes
### Test 


docker-compose up -d
docker-compose down -v
docker-compose up --build

# deleyt index
curl -X DELETE -u elastic:b2ecc628566048608451c61b6b210ee6467edc7aefa911efafe4e4c7673f17a8 "http://localhost:9200/logs"

#  create token
curl -X POST -u elastic:b2ecc628566048608451c61b6b210ee6467edc7aefa911efafe4e4c7673f17a8 "localhost:9200/_security/service/elastic/kibana/credential/token/kibana_token?pretty"

docker-compose --env-file .env up -d
docker exec -it kibana env | Select-String "ELASTICSEARCH_SERVICEACCOUNTTOKEN"

# check kafka produce
docker exec -it kafka-0 bash
cd /opt/bitnami/kafka/bin/
./kafka-console-consumer.sh --bootstrap-server kafka-0:9092 --topic logs --from-beginning

docker exec -it kafka-0 bash
kafka-consumer-groups.sh --bootstrap-server kafka-0:9092 --list
kafka-consumer-groups.sh --bootstrap-server kafka-0:9092 --group logstash --describe

# A faire 
Service des demandes de pr√™t (cr√©ation et validation des dossiers)
‚Ä¢ Service de v√©rification du cr√©dit (√©valuation des ant√©c√©dents du client)
‚Ä¢ Service d‚Äô√©valuation du bien (analyse de la valeur du bien)
‚Ä¢ Service de d√©cision (approbation ou rejet de la demande)
‚Ä¢ Service de notification (envoi des r√©sultats aux clients)

 curl -X DELET-u elastic:b2ecc628566048608451c61b6b210ee6467edc7aefa911efafe4e4c7673f17a8 "http://localhost:9200/logs"

streamlit run stFrontEnd/main.py

docker exec -it krabbitmq bash      
rabbitmqctl change_password rabbitmq b2ecc628566048608451c61b6b210ee6467edc7aefa911efafe4e4c7673f17a8
Shawn901@gmail.com
